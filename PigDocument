PIG:

 Pig is a high-level language platform for analyzing and querying huge dataset that are stored in HDFS. Pig as a component of Hadoop Ecosystem uses PigLatin language. It is very similar to SQL. It loads the data, applies the required filters and dumps the data in the required format. For Programs execution, pig requires Java runtime environment.

It is a highlevel data processing language which provides a rich set of data types and operators to perform various operations on the data.

To perform a particular task Programmers using Pig, programmers need to write a Pig script using the Pig Latin language, and execute them using any of the execution mechanisms (Grunt Shell, UDFs, Embedded). After execution, these scripts will go through a series of transformations applied by the Pig Framework, to produce the desired output.

Internally, Apache Pig converts these scripts into a series of MapReduce jobs, and thus, it makes the programmer’s job easy.

Rich set of operators − It provides many operators to perform operations like join, sort, filer, etc.

Ease of programming − Pig Latin is similar to SQL and it is easy to write a Pig script if you are good at SQL.

Optimization opportunities − The tasks in Apache Pig optimize their execution automatically, so the programmers need to focus only on semantics of the language.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

1)b)
register /usr/local/hive/lib/hive-exec-1.2.1.jar;

register /usr/local/hive/lib/hive-common-1.2.1.jar;

data1 = LOAD 'hdfs://localhost:54310/user/hive/warehouse/visa.db/h1b_final' USING PigStorage('\t') as (s_no:double,case_status:chararray,employer_name:chararray,soc_name:chararray,job_title:chararray,full_time_position:chararray,prevailing_wage:double,year:chararray,worksite:chararray,longitude,latitude);
data2= FILTER data1 by year=='2011';
data3= group data2 by $4;
data4= foreach data3 generate group, COUNT($1);
data5= FILTER data1 by year=='2012';
data6= group data5 by $4;
data7= foreach data6 generate group, COUNT($1);
data8= FILTER data1 by year=='2013';
data9= group data8 by $4;
data10= foreach data9 generate group, COUNT($1);
data11= FILTER data1 by year=='2014';
data12= group data11 by $4;
data13= foreach data12 generate group, COUNT($1);
data14= FILTER data1 by year=='2015';
data15= group data14 by $4;
data16= foreach data15 generate group, COUNT($1);
data17= FILTER data1 by year=='2016';
data18= group data17 by $4;
data19= foreach data18 generate group, COUNT($1);
data20= join data4 by $0,data7 by $0,data10 by $0,data13 by $0,data16 by $0,data19 by $0;
data21= foreach data20 generate $0,$1,$3,$5,$7,$9,$11;
data22= foreach data21  generate $0,(float)($6-$5)*100/$5,(float)($5-$4)*100/$4,(float)($4-$3)*100/$3,(float)($3-$2)*100/$2,(float)($2-$1)*100/$1;
data23= foreach data22 generate $0,($1+$2+$3+$4+$5)/5;
data24= order data23 by $1 desc;
dump data24;

6)
register /usr/local/hive/lib/hive-exec-1.2.1.jar;

register /usr/local/hive/lib/hive-common-1.2.1.jar;

data1 = LOAD 'hdfs://localhost:54310/user/hive/warehouse/visa.db/h1b_final' USING PigStorage('\t') as (s_no:double,case_status:chararray,employer_name:chararray,soc_name:chararray,job_title:chararray,full_time_position:chararray,prevailing_wage:double,year:chararray,worksite:chararray,longitude,latitude);
 	
data2= FILTER data1 by year=='2011';

data3= group data2 by $7;

data4= foreach data3 generate group, COUNT($1);

data5= FILTER data1 by year=='2012';

data6= group data5 by $7;

data7= foreach data6 generate group, COUNT($1);

data8= FILTER data1 by year=='2013';

data9= group data8 by $7;

data10= foreach data9 generate group, COUNT($1);

data11= FILTER data1 by year=='2014';

data12= group data11 by $7;

data13= foreach data12 generate group, COUNT($1);

data14= FILTER data1 by year=='2015';

data15= group data14 by $7;

data16= foreach data15 generate group, COUNT($1);

data17= FILTER data1 by year=='2016';

data18= group data17 by $7;

data19= foreach data18 generate group, COUNT($1);

data20= FILTER data1 by year=='2011';

data21= group data20 by $1;

data22= foreach data21 generate group, COUNT($1);
  
data23= FILTER data1 by year=='2012';

data24= group data23 by $1;

data25= foreach data24 generate group, COUNT($1);

data26= FILTER data1 by year=='2013';

data27= group data26 by $1;

data28= foreach data27 generate group, COUNT($1);

data29= FILTER data1 by year=='2014';

data30= group data29 by $1;

data31= foreach data30 generate group, COUNT($1);

data32= FILTER data1 by year=='2015';

data33= group data32 by $1;

data34= foreach data33 generate group, COUNT($1);

data35= FILTER data1 by year=='2016';

data36= group data35 by $1;

data37= foreach data36 generate group, COUNT($1);

percentage2011= foreach data22 generate $0, (float)($1)/358767;

percentage2012= foreach data25 generate $0, (float)($1)/415607;
 
percentage2013= foreach data28 generate $0, (float)($1)/442114;

percentage2014= foreach data31 generate $0, (float)($1)/519427;

percentage2015= foreach data34 generate $0, (float)($1)/618727;

percentage2016= foreach data37 generate $0, (float)($1)/647803;

data38 = union percentage2011, percentage2012, percentage2013, percentage2014, percentage2015, percentage2016;
dump data38;

8)a)
register /usr/local/hive/lib/hive-exec-1.2.1.jar;
register /usr/local/hive/lib/hive-common-1.2.1.jar;
data1 = LOAD 'hdfs://localhost:54310/user/hive/warehouse/visa.db/h1b_final' USING PigStorage('\t') as (s_no:double,case_status:chararray,employer_name:chararray,soc_name:chararray,job_title:chararray,full_time_position:chararray,prevailing_wage:double,year:chararray,worksite:chararray,longitude,latitude);
data3= FILTER data1 BY case_status=='CERTIFIED' or case_status=='CERTIFIED-WITHDRAWN';
data4= FILTER data3 BY full_time_position=='Y';
data6= foreach data4 generate $1,$4,$5,$6,$7;
data7= group data6 by $4;
data8 = foreach data7 generate group,ROUND_TO(AVG(data6.prevailing_wage),2) as avg_wage;
dump data8;

8)b)
register /usr/local/hive/lib/hive-exec-1.2.1.jar;
register /usr/local/hive/lib/hive-common-1.2.1.jar;
data1 = LOAD 'hdfs://localhost:54310/user/hive/warehouse/visa.db/h1b_final' USING PigStorage('\t') as (s_no:double,case_status:chararray,employer_name:chararray,soc_name:chararray,job_title:chararray,full_time_position:chararray,prevailing_wage:double,year:chararray,worksite:chararray,longitude,latitude);
data3= FILTER data1 BY case_status=='CERTIFIED' or case_status=='CERTIFIED-WITHDRAWN';
data4= FILTER data3 BY full_time_position=='N';
data6= foreach data4 generate $1,$4,$5,$6,$7;
data7= group data6 by $4;
data8 = foreach data7 generate group,ROUND_TO(AVG(data6.prevailing_wage),2) as avg_wage;
dump data8;

9)Which are the employers along with the number of petitions who have the success rate more than 70%  in petitions. (total petitions filed 1000 OR more than 1000) ? Display the values in descending order of success rate.

register /usr/local/hive/lib/hive-exec-1.2.1.jar;
register /usr/local/hive/lib/hive-common-1.2.1.jar;
data1 = LOAD 'hdfs://localhost:54310/user/hive/warehouse/visa.db/h1b_final' USING PigStorage('\t') as (s_no:double,case_status:chararray,employer_name:chararray,soc_name:chararray,job_title:chararray,full_time_position:chararray,prevailing_wage:double,year:chararray,worksite:chararray,longitude,latitude);
data2= filter data1 by case_status =='CERTIFIED';
data3= filter data1 by case_status =='CERTIFIED-WITHDRAWN';
data4 = group data2 by LOWER($2);
data5= foreach data4 generate group ,COUNT($1);
data6 = group data3 by LOWER($2);
data7= foreach data6 generate group ,COUNT($1);
data8= group data1 by LOWER($2);
data9= foreach data8 generate group ,COUNT($1);
data10= join data5 by $0, data7 by $0, data9 by $0;
data11 = foreach data10 generate $0,(double)($1+$3)*100/$5;
data12 = filter data11 by $1>70;
data13 = order data12 by $1 desc;
dump data13;
10)Which are the  job positions along with the number of petitions which have the success rate more than 70%  in petitions (total petitions filed 1000 OR more than 1000)? Display the values in descending order of success rate.

register /usr/local/hive/lib/hive-exec-1.2.1.jar;
register /usr/local/hive/lib/hive-common-1.2.1.jar;
data1 = LOAD 'hdfs://localhost:54310/user/hive/warehouse/visa.db/h1b_final' USING PigStorage('\t') as (s_no:double,case_status:chararray,employer_name:chararray,soc_name:chararray,job_title:chararray,full_time_position:chararray,prevailing_wage:double,year:chararray,worksite:chararray,longitude,latitude);
data2= filter data1 by case_status =='CERTIFIED';
data3= filter data1 by case_status =='CERTIFIED-WITHDRAWN';
data4 = group data2 by LOWER($4);
data5= foreach data4 generate group ,COUNT($1);
data6 = group data3 by LOWER($4);
data7= foreach data6 generate group ,COUNT($1);
data8= group data1 by LOWER($4);
data9= foreach data8 generate group ,COUNT($1);
data10= join data5 by $0, data7 by $0, data9 by $0;
data11 = foreach data10 generate $0,(double)($1+$3)*100/$5;
data12 = filter data11 by $1>70;
data13 = order data12 by $1 desc;
dump data13;


